{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad7cf796-8b1f-4a59-9c96-144a9c7399e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 02_silver_transforms.py\n",
    "#\n",
    "# PURPOSE\n",
    "# -------\n",
    "# Transform Unity Catalog Bronze raw tables (all columns as STRING) into Silver tables:\n",
    "#   - Clean IDs and text columns (trim, lower/upper)\n",
    "#   - Safely cast numerics using try_cast (malformed -> NULL)\n",
    "#   - Safely parse timestamps using to_timestamp (unparseable -> NULL)\n",
    "#   - Deduplicate by business keys using latest ingested_at\n",
    "#   - Write Unity Catalog managed Delta tables (saveAsTable)\n",
    "#\n",
    "# WHY SILVER\n",
    "# ----------\n",
    "# Bronze is raw and stable (no schema inference, no casting, append safe).\n",
    "# Silver is curated: correct types, consistent formatting, fewer duplicates.\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Imports (Spark DataFrame column functions)\n",
    "# ----------------------------\n",
    "\n",
    "from pyspark.sql.functions import col  # Reference a column by name (builds an expression)\n",
    "from pyspark.sql.functions import trim  # Remove leading/trailing whitespace from strings\n",
    "from pyspark.sql.functions import lower  # Convert string to lowercase for consistency\n",
    "from pyspark.sql.functions import upper  # Convert string to uppercase (e.g., state codes)\n",
    "from pyspark.sql.functions import to_timestamp  # Convert a string into timestamp (bad parse -> NULL)\n",
    "from pyspark.sql.functions import to_date  # Convert timestamp into date (for time-series grouping)\n",
    "from pyspark.sql.functions import coalesce  # Pick first non-null value among expressions\n",
    "from pyspark.sql.functions import current_timestamp  # Current processing time (fallback for ordering)\n",
    "from pyspark.sql.functions import row_number  # Window function used for deduplication\n",
    "from pyspark.sql.functions import expr  # Allows SQL expressions like try_cast(...)\n",
    "from pyspark.sql.window import Window  # Defines partition/order rules for window functions\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Configuration (catalog/schema + behavior)\n",
    "# ----------------------------\n",
    "\n",
    "BRONZE_SCHEMA = \"olist.bronze\"  # Where raw tables live\n",
    "SILVER_SCHEMA = \"olist.silver\"  # Where curated silver tables will be written\n",
    "\n",
    "SILVER_WRITE_MODE = \"overwrite\"  # Rebuild silver each time (simple for capstone)\n",
    "\n",
    "KEEP_LINEAGE_COLS = True  # Keep Bronze audit columns (ingested_at/source_file/source_system) in Silver\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Create the Silver schema if it does not exist\n",
    "# ----------------------------\n",
    "\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {SILVER_SCHEMA}\")  # Idempotent schema creation\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Helper: Write a managed UC Delta table\n",
    "# ----------------------------\n",
    "\n",
    "def write_silver_table(df, table_name: str):\n",
    "    \"\"\"\n",
    "    Write df to Unity Catalog as a managed Delta table: olist.silver.<table_name>\n",
    "    We use saveAsTable() so UC manages storage location (no LOCATION paths).\n",
    "    \"\"\"\n",
    "\n",
    "    full_name = f\"{SILVER_SCHEMA}.{table_name}\"  # Build fully-qualified UC name\n",
    "\n",
    "    (  # Begin write chain\n",
    "        df.write  # Spark DataFrame writer\n",
    "        .format(\"delta\")  # Delta Lake format\n",
    "        .mode(SILVER_WRITE_MODE)  # Overwrite for rebuild style\n",
    "        .option(\"overwriteSchema\", \"true\")  # Allow schema evolution on overwrite\n",
    "        .saveAsTable(full_name)  # Write managed UC table\n",
    "    )  # End write chain\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Helper: Deduplicate keeping latest record by timestamp\n",
    "# ----------------------------\n",
    "\n",
    "def dedupe_latest(df, key_cols: list, ts_col: str):\n",
    "    \"\"\"\n",
    "    Deduplicate df by key_cols, keeping only the latest row according to ts_col.\n",
    "    We use ingested_at (from Bronze) as the 'latest' signal.\n",
    "    \"\"\"\n",
    "\n",
    "    ordering_expr = coalesce(col(ts_col), current_timestamp())  # Prefer ts_col, fallback to now\n",
    "    w = Window.partitionBy(*[col(c) for c in key_cols]).orderBy(ordering_expr.desc())  # Window by keys, latest first\n",
    "    df_ranked = df.withColumn(\"_rn\", row_number().over(w))  # Add row number per partition\n",
    "    df_deduped = df_ranked.filter(col(\"_rn\") == 1).drop(\"_rn\")  # Keep only newest row, drop helper column\n",
    "    return df_deduped  # Return cleaned dataframe\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) Load Bronze tables (all raw columns are strings)\n",
    "# ============================================================\n",
    "\n",
    "orders_raw = spark.table(f\"{BRONZE_SCHEMA}.orders_raw\")  # Orders\n",
    "customers_raw = spark.table(f\"{BRONZE_SCHEMA}.customers_raw\")  # Customers\n",
    "order_items_raw = spark.table(f\"{BRONZE_SCHEMA}.order_items_raw\")  # Order items\n",
    "order_payments_raw = spark.table(f\"{BRONZE_SCHEMA}.order_payments_raw\")  # Payments\n",
    "products_raw = spark.table(f\"{BRONZE_SCHEMA}.products_raw\")  # Products\n",
    "sellers_raw = spark.table(f\"{BRONZE_SCHEMA}.sellers_raw\")  # Sellers\n",
    "order_reviews_raw = spark.table(f\"{BRONZE_SCHEMA}.order_reviews_raw\")  # Reviews\n",
    "category_translation_raw = spark.table(f\"{BRONZE_SCHEMA}.category_translation_raw\")  # Category translation\n",
    "# geolocation_raw exists but is optional in Silver; we'll keep it bronze-only for now.\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) SILVER: orders\n",
    "# ============================================================\n",
    "\n",
    "orders_silver = (  # Start orders transformations\n",
    "    orders_raw  # Source data\n",
    "    .withColumn(\"order_id\", trim(col(\"order_id\")))  # Clean IDs: remove whitespace\n",
    "    .withColumn(\"customer_id\", trim(col(\"customer_id\")))  # Clean IDs\n",
    "    .withColumn(\"order_status\", lower(trim(col(\"order_status\"))))  # Normalize status for consistent grouping\n",
    "\n",
    "    # Parse timestamps (if parse fails, result becomes NULL, which is okay in Silver)\n",
    "    .withColumn(\"order_purchase_ts\", to_timestamp(col(\"order_purchase_timestamp\")))  # Purchase timestamp\n",
    "    .withColumn(\"order_approved_ts\", to_timestamp(col(\"order_approved_at\")))  # Approved timestamp\n",
    "    .withColumn(\"order_delivered_carrier_ts\", to_timestamp(col(\"order_delivered_carrier_date\")))  # Carrier delivery timestamp\n",
    "    .withColumn(\"order_delivered_customer_ts\", to_timestamp(col(\"order_delivered_customer_date\")))  # Customer delivery timestamp\n",
    "    .withColumn(\"order_estimated_delivery_ts\", to_timestamp(col(\"order_estimated_delivery_date\")))  # Estimated delivery timestamp\n",
    "\n",
    "    # Derive a date column for easy time-series analysis (daily aggregations)\n",
    "    .withColumn(\"order_purchase_date\", to_date(col(\"order_purchase_ts\")))\n",
    ")\n",
    "\n",
    "orders_cols = [  # Columns we keep in orders silver\n",
    "    \"order_id\",\n",
    "    \"customer_id\",\n",
    "    \"order_status\",\n",
    "    \"order_purchase_ts\",\n",
    "    \"order_purchase_date\",\n",
    "    \"order_approved_ts\",\n",
    "    \"order_delivered_carrier_ts\",\n",
    "    \"order_delivered_customer_ts\",\n",
    "    \"order_estimated_delivery_ts\",\n",
    "]\n",
    "\n",
    "if KEEP_LINEAGE_COLS:  # Keep Bronze audit columns if enabled\n",
    "    orders_cols += [\"ingested_at\", \"source_file\", \"source_system\"]\n",
    "\n",
    "orders_silver = orders_silver.select(*orders_cols)  # Select final columns\n",
    "orders_silver = dedupe_latest(orders_silver, [\"order_id\"], \"ingested_at\")  # Deduplicate orders\n",
    "write_silver_table(orders_silver, \"orders\")  # Write olist.silver.orders\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 7) SILVER: customers\n",
    "# ============================================================\n",
    "\n",
    "customers_silver = (  # Start customers transformations\n",
    "    customers_raw\n",
    "    .withColumn(\"customer_id\", trim(col(\"customer_id\")))  # Clean customer_id\n",
    "    .withColumn(\"customer_unique_id\", trim(col(\"customer_unique_id\")))  # Clean unique id\n",
    "    .withColumn(\"customer_zip_code_prefix\", trim(col(\"customer_zip_code_prefix\")))  # Keep as string, trim spaces\n",
    "    .withColumn(\"customer_city\", lower(trim(col(\"customer_city\"))))  # Normalize city\n",
    "    .withColumn(\"customer_state\", upper(trim(col(\"customer_state\"))))  # Normalize state (SP, RJ, etc.)\n",
    ")\n",
    "\n",
    "customers_cols = [\n",
    "    \"customer_id\",\n",
    "    \"customer_unique_id\",\n",
    "    \"customer_zip_code_prefix\",\n",
    "    \"customer_city\",\n",
    "    \"customer_state\",\n",
    "]\n",
    "\n",
    "if KEEP_LINEAGE_COLS:\n",
    "    customers_cols += [\"ingested_at\", \"source_file\", \"source_system\"]\n",
    "\n",
    "customers_silver = customers_silver.select(*customers_cols)  # Select final columns\n",
    "customers_silver = dedupe_latest(customers_silver, [\"customer_id\"], \"ingested_at\")  # Deduplicate by customer_id\n",
    "write_silver_table(customers_silver, \"customers\")  # Write olist.silver.customers\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 8) SILVER: order_items\n",
    "# ============================================================\n",
    "\n",
    "order_items_silver = (\n",
    "    order_items_raw\n",
    "    .withColumn(\"order_id\", trim(col(\"order_id\")))  # Clean order_id\n",
    "    .withColumn(\"order_item_id\", expr(\"try_cast(order_item_id as int)\"))  # Safe int cast; bad -> NULL\n",
    "    .withColumn(\"product_id\", trim(col(\"product_id\")))  # Clean product_id\n",
    "    .withColumn(\"seller_id\", trim(col(\"seller_id\")))  # Clean seller_id\n",
    "    .withColumn(\"shipping_limit_ts\", to_timestamp(col(\"shipping_limit_date\")))  # Parse timestamp\n",
    "    .withColumn(\"price\", expr(\"try_cast(price as double)\"))  # Safe numeric cast\n",
    "    .withColumn(\"freight_value\", expr(\"try_cast(freight_value as double)\"))  # Safe numeric cast\n",
    ")\n",
    "\n",
    "order_items_cols = [\n",
    "    \"order_id\",\n",
    "    \"order_item_id\",\n",
    "    \"product_id\",\n",
    "    \"seller_id\",\n",
    "    \"shipping_limit_ts\",\n",
    "    \"price\",\n",
    "    \"freight_value\",\n",
    "]\n",
    "\n",
    "if KEEP_LINEAGE_COLS:\n",
    "    order_items_cols += [\"ingested_at\", \"source_file\", \"source_system\"]\n",
    "\n",
    "order_items_silver = order_items_silver.select(*order_items_cols)\n",
    "order_items_silver = dedupe_latest(order_items_silver, [\"order_id\", \"order_item_id\"], \"ingested_at\")\n",
    "write_silver_table(order_items_silver, \"order_items\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 9) SILVER: order_payments\n",
    "# ============================================================\n",
    "\n",
    "order_payments_silver = (\n",
    "    order_payments_raw\n",
    "    .withColumn(\"order_id\", trim(col(\"order_id\")))  # Clean order_id\n",
    "    .withColumn(\"payment_sequential\", expr(\"try_cast(payment_sequential as int)\"))  # Safe int cast\n",
    "    .withColumn(\"payment_type\", lower(trim(col(\"payment_type\"))))  # Normalize payment type\n",
    "    .withColumn(\"payment_installments\", expr(\"try_cast(payment_installments as int)\"))  # Safe int cast\n",
    "    .withColumn(\"payment_value\", expr(\"try_cast(payment_value as double)\"))  # Safe double cast\n",
    ")\n",
    "\n",
    "payments_cols = [\n",
    "    \"order_id\",\n",
    "    \"payment_sequential\",\n",
    "    \"payment_type\",\n",
    "    \"payment_installments\",\n",
    "    \"payment_value\",\n",
    "]\n",
    "\n",
    "if KEEP_LINEAGE_COLS:\n",
    "    payments_cols += [\"ingested_at\", \"source_file\", \"source_system\"]\n",
    "\n",
    "order_payments_silver = order_payments_silver.select(*payments_cols)\n",
    "order_payments_silver = dedupe_latest(order_payments_silver, [\"order_id\", \"payment_sequential\"], \"ingested_at\")\n",
    "write_silver_table(order_payments_silver, \"order_payments\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 10) SILVER: products\n",
    "# ============================================================\n",
    "\n",
    "products_silver = (\n",
    "    products_raw\n",
    "    .withColumn(\"product_id\", trim(col(\"product_id\")))  # Clean product_id\n",
    "    .withColumn(\"product_category_name\", lower(trim(col(\"product_category_name\"))))  # Normalize category\n",
    "    # Olist column names contain typos (e.g., product_name_lenght). We keep the same names but cast safely.\n",
    "    .withColumn(\"product_name_lenght\", expr(\"try_cast(product_name_lenght as int)\"))  # Safe int cast\n",
    "    .withColumn(\"product_description_lenght\", expr(\"try_cast(product_description_lenght as int)\"))  # Safe int cast\n",
    "    .withColumn(\"product_photos_qty\", expr(\"try_cast(product_photos_qty as int)\"))  # Safe int cast\n",
    "    .withColumn(\"product_weight_g\", expr(\"try_cast(product_weight_g as int)\"))  # Safe int cast\n",
    "    .withColumn(\"product_length_cm\", expr(\"try_cast(product_length_cm as int)\"))  # Safe int cast\n",
    "    .withColumn(\"product_height_cm\", expr(\"try_cast(product_height_cm as int)\"))  # Safe int cast\n",
    "    .withColumn(\"product_width_cm\", expr(\"try_cast(product_width_cm as int)\"))  # Safe int cast\n",
    ")\n",
    "\n",
    "products_cols = [\n",
    "    \"product_id\",\n",
    "    \"product_category_name\",\n",
    "    \"product_name_lenght\",\n",
    "    \"product_description_lenght\",\n",
    "    \"product_photos_qty\",\n",
    "    \"product_weight_g\",\n",
    "    \"product_length_cm\",\n",
    "    \"product_height_cm\",\n",
    "    \"product_width_cm\",\n",
    "]\n",
    "\n",
    "if KEEP_LINEAGE_COLS:\n",
    "    products_cols += [\"ingested_at\", \"source_file\", \"source_system\"]\n",
    "\n",
    "products_silver = products_silver.select(*products_cols)\n",
    "products_silver = dedupe_latest(products_silver, [\"product_id\"], \"ingested_at\")\n",
    "write_silver_table(products_silver, \"products\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 11) SILVER: sellers\n",
    "# ============================================================\n",
    "\n",
    "sellers_silver = (\n",
    "    sellers_raw\n",
    "    .withColumn(\"seller_id\", trim(col(\"seller_id\")))  # Clean seller_id\n",
    "    .withColumn(\"seller_zip_code_prefix\", trim(col(\"seller_zip_code_prefix\")))  # Keep as string, trim\n",
    "    .withColumn(\"seller_city\", lower(trim(col(\"seller_city\"))))  # Normalize city\n",
    "    .withColumn(\"seller_state\", upper(trim(col(\"seller_state\"))))  # Normalize state\n",
    ")\n",
    "\n",
    "sellers_cols = [\n",
    "    \"seller_id\",\n",
    "    \"seller_zip_code_prefix\",\n",
    "    \"seller_city\",\n",
    "    \"seller_state\",\n",
    "]\n",
    "\n",
    "if KEEP_LINEAGE_COLS:\n",
    "    sellers_cols += [\"ingested_at\", \"source_file\", \"source_system\"]\n",
    "\n",
    "sellers_silver = sellers_silver.select(*sellers_cols)\n",
    "sellers_silver = dedupe_latest(sellers_silver, [\"seller_id\"], \"ingested_at\")\n",
    "write_silver_table(sellers_silver, \"sellers\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 12) SILVER: order_reviews (safe casting with try_cast)\n",
    "# ============================================================\n",
    "\n",
    "# ============================================================\n",
    "# 12) SILVER: order_reviews (STRICT-CAST SAFE VERSION)\n",
    "# Why this fix:\n",
    "#   - Some rows contain text in a field we try to interpret as timestamp\n",
    "#   - Under Photon/ANSI behavior, strict casts can throw errors\n",
    "#   - try_cast(...) returns NULL instead of failing the job\n",
    "# ============================================================\n",
    "\n",
    "# Build the order_reviews silver DataFrame from the bronze raw table\n",
    "order_reviews_silver = (\n",
    "    order_reviews_raw  # Start from Bronze reviews (all columns are strings)\n",
    "    .withColumn(\"review_id\", trim(col(\"review_id\")).cast(\"string\"))  # Ensure review_id is clean string\n",
    "    .withColumn(\"order_id\", trim(col(\"order_id\")).cast(\"string\"))  # Ensure order_id is clean string\n",
    "\n",
    "    # Safely cast review_score to int; malformed values become NULL instead of failing\n",
    "    .withColumn(\"review_score\", expr(\"try_cast(review_score as int)\"))\n",
    "\n",
    "    # Keep comment fields as strings (these can contain commas/quotes and should NOT be cast)\n",
    "    .withColumn(\"review_comment_title\", col(\"review_comment_title\").cast(\"string\"))\n",
    "    .withColumn(\"review_comment_message\", col(\"review_comment_message\").cast(\"string\"))\n",
    "\n",
    "    # Safely parse timestamps using try_cast to tolerate malformed inputs (returns NULL)\n",
    "    .withColumn(\"review_creation_ts\", expr(\"try_cast(review_creation_date as timestamp)\"))\n",
    "    .withColumn(\"review_answer_ts\", expr(\"try_cast(review_answer_timestamp as timestamp)\"))\n",
    ")\n",
    "\n",
    "# Define the exact output columns (stable schema helps prevent drift)\n",
    "reviews_cols = [\n",
    "    \"review_id\",  # Review key\n",
    "    \"order_id\",  # FK to orders\n",
    "    \"review_score\",  # Score (int or NULL)\n",
    "    \"review_comment_title\",  # Title (string)\n",
    "    \"review_comment_message\",  # Message (string)\n",
    "    \"review_creation_ts\",  # Creation timestamp (timestamp or NULL)\n",
    "    \"review_answer_ts\",  # Answer timestamp (timestamp or NULL)\n",
    "]\n",
    "\n",
    "# Optionally keep lineage columns so you can trace back to files and ingestion time\n",
    "if KEEP_LINEAGE_COLS:\n",
    "    reviews_cols += [\"ingested_at\", \"source_file\", \"source_system\"]\n",
    "\n",
    "# Select final columns only (prevents accidental extra columns from sneaking in)\n",
    "order_reviews_silver = order_reviews_silver.select(*reviews_cols)\n",
    "\n",
    "# Deduplicate by review_id keeping the latest ingested record\n",
    "order_reviews_silver = dedupe_latest(order_reviews_silver, [\"review_id\"], \"ingested_at\")\n",
    "\n",
    "# Write the managed UC silver table\n",
    "write_silver_table(order_reviews_silver, \"order_reviews\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 13) SILVER: category_translation\n",
    "# ============================================================\n",
    "\n",
    "category_translation_silver = (\n",
    "    category_translation_raw\n",
    "    .withColumn(\"product_category_name\", lower(trim(col(\"product_category_name\"))))  # Normalize Portuguese category\n",
    "    .withColumn(\"product_category_name_english\", lower(trim(col(\"product_category_name_english\"))))  # Normalize English label\n",
    ")\n",
    "\n",
    "translation_cols = [\n",
    "    \"product_category_name\",\n",
    "    \"product_category_name_english\",\n",
    "]\n",
    "\n",
    "if KEEP_LINEAGE_COLS:\n",
    "    translation_cols += [\"ingested_at\", \"source_file\", \"source_system\"]\n",
    "\n",
    "category_translation_silver = category_translation_silver.select(*translation_cols)\n",
    "category_translation_silver = dedupe_latest(category_translation_silver, [\"product_category_name\"], \"ingested_at\")\n",
    "write_silver_table(category_translation_silver, \"category_translation\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 14) Validation: Row counts for Silver tables\n",
    "# ============================================================\n",
    "\n",
    "silver_tables = [\n",
    "    \"orders\",\n",
    "    \"customers\",\n",
    "    \"order_items\",\n",
    "    \"order_payments\",\n",
    "    \"products\",\n",
    "    \"sellers\",\n",
    "    \"order_reviews\",\n",
    "    \"category_translation\",\n",
    "]\n",
    "\n",
    "for t in silver_tables:\n",
    "    display(\n",
    "        spark.sql(\n",
    "            f\"SELECT '{SILVER_SCHEMA}.{t}' AS table_name, COUNT(*) AS row_count FROM {SILVER_SCHEMA}.{t}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 15) Quick function explanations (brief, practical)\n",
    "# ============================================================\n",
    "#\n",
    "# trim(col(\"x\"))\n",
    "#   - Removes spaces at the start/end of strings (prevents join keys from mismatching).\n",
    "#\n",
    "# lower(col(\"x\")) / upper(col(\"x\"))\n",
    "#   - Normalizes text to consistent case so grouping and filtering behave consistently.\n",
    "#\n",
    "# to_timestamp(col(\"x\"))\n",
    "#   - Attempts to parse a string into a timestamp.\n",
    "#   - If parsing fails, Spark returns NULL (tolerant behavior).\n",
    "#\n",
    "# expr(\"try_cast(x as int)\")\n",
    "#   - Safely casts string column x to int.\n",
    "#   - If x is malformed (e.g., '2018-04-01 00:27:51'), returns NULL instead of error.\n",
    "#\n",
    "# Window + row_number()\n",
    "#   - Used to deduplicate data:\n",
    "#     partitionBy(keys) groups rows by business key\n",
    "#     orderBy(latest ingested_at) chooses newest record\n",
    "#     row_number == 1 keeps only one row per key\n",
    "#\n",
    "# saveAsTable()\n",
    "#   - Writes a managed Unity Catalog table.\n",
    "#   - You do NOT supply a storage path (UC handles it).\n",
    "# ============================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5c64d06-dca4-4a35-a99d-88f492c3442d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 12A) DATA QUALITY CHECKS: order_reviews (NON-BLOCKING)\n",
    "# ============================================================\n",
    "\n",
    "# Reload the silver table we just wrote (ensures we validate persisted data)\n",
    "order_reviews_silver_df = spark.table(\"olist.silver.order_reviews\")\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Total row count\n",
    "# ----------------------------\n",
    "\n",
    "total_reviews = order_reviews_silver_df.count()  # Total number of review records\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Malformed timestamp checks\n",
    "# ----------------------------\n",
    "\n",
    "# Count rows where creation timestamp failed to parse\n",
    "bad_creation_ts = order_reviews_silver_df.filter(\n",
    "    col(\"review_creation_ts\").isNull()\n",
    ").count()\n",
    "\n",
    "# Count rows where answer timestamp failed to parse\n",
    "bad_answer_ts = order_reviews_silver_df.filter(\n",
    "    col(\"review_answer_ts\").isNull()\n",
    ").count()\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Review score validity check\n",
    "# ----------------------------\n",
    "\n",
    "# Valid review scores should be between 1 and 5\n",
    "invalid_review_scores = order_reviews_silver_df.filter(\n",
    "    (col(\"review_score\").isNull()) |  # NULL after try_cast\n",
    "    (col(\"review_score\") < 1) |       # Less than valid range\n",
    "    (col(\"review_score\") > 5)         # Greater than valid range\n",
    ").count()\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Print DQ summary (human-readable)\n",
    "# ----------------------------\n",
    "\n",
    "print(\"========== DATA QUALITY REPORT: olist.silver.order_reviews ==========\")\n",
    "print(f\"Total rows                  : {total_reviews}\")\n",
    "print(f\"Bad creation timestamps     : {bad_creation_ts}\")\n",
    "print(f\"Bad answer timestamps       : {bad_answer_ts}\")\n",
    "print(f\"Invalid review scores (1â€“5) : {invalid_review_scores}\")\n",
    "print(\"=====================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3f825c2-fbf2-408b-8898-793b9ad8f2ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(\n",
    "    order_reviews_silver_df\n",
    "    .filter(col(\"review_creation_ts\").isNull())\n",
    "    .select(\"review_id\", \"review_comment_message\", \"review_creation_ts\")\n",
    "    .limit(20)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_silver_transform.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
